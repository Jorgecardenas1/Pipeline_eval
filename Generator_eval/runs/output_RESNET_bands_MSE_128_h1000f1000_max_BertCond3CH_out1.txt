cuda:0
Predictor_RESNET(
  (l1): Linear(in_features=38400, out_features=49152, bias=False)
  (model): ResNet(
    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=False)
      (1): Linear(in_features=2048, out_features=1000, bias=False)
      (2): Linear(in_features=1000, out_features=1000, bias=False)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=1000, out_features=1, bias=False)
    )
  )
  (linear): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=False)
    (1): Linear(in_features=2048, out_features=1000, bias=False)
    (2): Linear(in_features=1000, out_features=1000, bias=False)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1000, out_features=1, bias=False)
  )
)
Epoch 0/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[1,    99] loss: 0.001 running loss:  0.074
accuracy: -0.159 
Score: 0.068 
learning_rate:  [1.94e-05]
learning_rate:  [1.94e-05]
mean Acc per epoch -0.13995655214215438
Epoch 1/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[2,    99] loss: 0.001 running loss:  0.065
accuracy: -0.051 
Score: -0.096 
learning_rate:  [1.8818e-05]
learning_rate:  [1.8818e-05]
mean Acc per epoch -0.024034200557946243
Epoch 2/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[3,    99] loss: 0.001 running loss:  0.062
accuracy: 0.015 
Score: -0.013 
learning_rate:  [1.8253459999999998e-05]
learning_rate:  [1.8253459999999998e-05]
mean Acc per epoch 0.013526228631607056
Epoch 3/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[4,    99] loss: 0.001 running loss:  0.059
accuracy: 0.041 
Score: -0.290 
learning_rate:  [1.77058562e-05]
learning_rate:  [1.77058562e-05]
mean Acc per epoch 0.05103143271565574
Epoch 4/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[5,    99] loss: 0.001 running loss:  0.059
accuracy: 0.058 
Score: -0.047 
learning_rate:  [1.7174680513999998e-05]
learning_rate:  [1.7174680513999998e-05]
mean Acc per epoch 0.07128473542809279
Epoch 5/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[6,    99] loss: 0.000 running loss:  0.057
accuracy: 0.086 
Score: 0.282 
learning_rate:  [1.6659440098579996e-05]
learning_rate:  [1.6659440098579996e-05]
mean Acc per epoch 0.09723349777775718
Epoch 6/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[7,    99] loss: 0.001 running loss:  0.055
accuracy: 0.107 
Score: 0.185 
learning_rate:  [1.6159656895622596e-05]
learning_rate:  [1.6159656895622596e-05]
mean Acc per epoch 0.11203062399657801
Epoch 7/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[8,    99] loss: 0.001 running loss:  0.054
accuracy: 0.137 
Score: 0.183 
learning_rate:  [1.5674867188753917e-05]
learning_rate:  [1.5674867188753917e-05]
mean Acc per epoch 0.13096337961711133
Epoch 8/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[9,    99] loss: 0.001 running loss:  0.054
accuracy: 0.140 
Score: 0.210 
learning_rate:  [1.5204621173091299e-05]
learning_rate:  [1.5204621173091299e-05]
mean Acc per epoch 0.1521127995846032
Epoch 9/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[10,    99] loss: 0.001 running loss:  0.054
accuracy: 0.142 
Score: 0.086 
learning_rate:  [1.474848253789856e-05]
learning_rate:  [1.474848253789856e-05]
mean Acc per epoch 0.15078424297375861
Epoch 10/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[11,    99] loss: 0.001 running loss:  0.053
accuracy: 0.164 
Score: 0.170 
learning_rate:  [1.4306028061761602e-05]
learning_rate:  [1.4306028061761602e-05]
mean Acc per epoch 0.1594732253643768
Epoch 11/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[12,    99] loss: 0.001 running loss:  0.052
accuracy: 0.160 
Score: -0.085 
learning_rate:  [1.3876847219908753e-05]
learning_rate:  [1.3876847219908753e-05]
mean Acc per epoch 0.17140352502147574
Epoch 12/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[13,    99] loss: 0.001 running loss:  0.051
accuracy: 0.183 
Score: 0.160 
learning_rate:  [1.346054180331149e-05]
learning_rate:  [1.346054180331149e-05]
mean Acc per epoch 0.1878690841078081
Epoch 13/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[14,    99] loss: 0.001 running loss:  0.052
accuracy: 0.172 
Score: 0.234 
learning_rate:  [1.3056725549212145e-05]
learning_rate:  [1.3056725549212145e-05]
mean Acc per epoch 0.17700736182621354
Epoch 14/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[15,    99] loss: 0.001 running loss:  0.051
accuracy: 0.178 
Score: 0.219 
learning_rate:  [1.266502378273578e-05]
learning_rate:  [1.266502378273578e-05]
mean Acc per epoch 0.177129362746274
Epoch 15/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[16,    99] loss: 0.001 running loss:  0.050
accuracy: 0.208 
Score: 0.174 
learning_rate:  [1.2285073069253707e-05]
learning_rate:  [1.2285073069253707e-05]
mean Acc per epoch 0.1897353775625147
Epoch 16/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[17,    99] loss: 0.001 running loss:  0.050
accuracy: 0.184 
Score: 0.158 
learning_rate:  [1.1916520877176095e-05]
learning_rate:  [1.1916520877176095e-05]
mean Acc per epoch 0.1833771351291242
Epoch 17/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[18,    99] loss: 0.001 running loss:  0.050
accuracy: 0.192 
Score: 0.028 
learning_rate:  [1.1559025250860812e-05]
learning_rate:  [1.1559025250860812e-05]
mean Acc per epoch 0.1900317837909659
Epoch 18/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[19,    99] loss: 0.000 running loss:  0.052
accuracy: 0.176 
Score: 0.202 
learning_rate:  [1.1212254493334987e-05]
learning_rate:  [1.1212254493334987e-05]
mean Acc per epoch 0.19230560176213946
Epoch 19/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[20,    99] loss: 0.001 running loss:  0.050
accuracy: 0.200 
Score: 0.264 
learning_rate:  [1.0875886858534937e-05]
learning_rate:  [1.0875886858534937e-05]
mean Acc per epoch 0.20146537091043779
Epoch 20/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[21,    99] loss: 0.001 running loss:  0.050
accuracy: 0.209 
Score: 0.312 
learning_rate:  [1.0549610252778888e-05]
learning_rate:  [1.0549610252778888e-05]
mean Acc per epoch 0.20644080541329163
Epoch 21/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[22,    99] loss: 0.001 running loss:  0.050
accuracy: 0.196 
Score: -0.396 
learning_rate:  [1.023312194519552e-05]
learning_rate:  [1.023312194519552e-05]
mean Acc per epoch 0.20485810246163694
Epoch 22/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[23,    99] loss: 0.001 running loss:  0.047
accuracy: 0.238 
Score: 0.268 
learning_rate:  [9.926128286839655e-06]
learning_rate:  [9.926128286839655e-06]
mean Acc per epoch 0.23291262423039688
Epoch 23/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[24,    99] loss: 0.001 running loss:  0.050
accuracy: 0.202 
Score: 0.267 
learning_rate:  [9.628344438234465e-06]
learning_rate:  [9.628344438234465e-06]
mean Acc per epoch 0.22312024717157797
Epoch 24/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[25,    99] loss: 0.001 running loss:  0.048
accuracy: 0.233 
Score: 0.370 
learning_rate:  [9.33949410508743e-06]
learning_rate:  [9.33949410508743e-06]
mean Acc per epoch 0.23293085648969977
Epoch 25/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[26,    99] loss: 0.001 running loss:  0.047
accuracy: 0.241 
Score: 0.129 
learning_rate:  [9.059309281934807e-06]
learning_rate:  [9.059309281934807e-06]
mean Acc per epoch 0.236299721452107
Epoch 26/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[27,    99] loss: 0.001 running loss:  0.049
accuracy: 0.229 
Score: 0.054 
learning_rate:  [8.787530003476762e-06]
learning_rate:  [8.787530003476762e-06]
mean Acc per epoch 0.2363088617139054
Epoch 27/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[28,    99] loss: 0.001 running loss:  0.046
accuracy: 0.268 
Score: 0.297 
learning_rate:  [8.523904103372459e-06]
learning_rate:  [8.523904103372459e-06]
mean Acc per epoch 0.2595679895720762
Epoch 28/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[29,    99] loss: 0.001 running loss:  0.047
accuracy: 0.255 
Score: 0.165 
learning_rate:  [8.268186980271286e-06]
learning_rate:  [8.268186980271286e-06]
mean Acc per epoch 0.2529991078700209
Epoch 29/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[30,    99] loss: 0.001 running loss:  0.045
accuracy: 0.267 
Score: 0.295 
learning_rate:  [8.020141370863147e-06]
learning_rate:  [8.020141370863147e-06]
mean Acc per epoch 0.26105219355173287
Epoch 30/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[31,    99] loss: 0.001 running loss:  0.046
accuracy: 0.253 
Score: 0.184 
learning_rate:  [7.779537129737253e-06]
learning_rate:  [7.779537129737253e-06]
mean Acc per epoch 0.25202841584807456
Epoch 31/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[32,    99] loss: 0.001 running loss:  0.047
accuracy: 0.253 
Score: 0.407 
learning_rate:  [7.546151015845135e-06]
learning_rate:  [7.546151015845135e-06]
mean Acc per epoch 0.2660268027750713
Epoch 32/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[33,    99] loss: 0.001 running loss:  0.046
accuracy: 0.270 
Score: 0.343 
learning_rate:  [7.319766485369781e-06]
learning_rate:  [7.319766485369781e-06]
mean Acc per epoch 0.2691800058065003
Epoch 33/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[34,    99] loss: 0.001 running loss:  0.045
accuracy: 0.267 
Score: 0.206 
learning_rate:  [7.100173490808687e-06]
learning_rate:  [7.100173490808687e-06]
mean Acc per epoch 0.26693015042982166
Epoch 34/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[35,    99] loss: 0.001 running loss:  0.045
accuracy: 0.273 
Score: 0.185 
learning_rate:  [6.8871682860844266e-06]
learning_rate:  [6.8871682860844266e-06]
mean Acc per epoch 0.2792225272666877
Epoch 35/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[36,    99] loss: 0.001 running loss:  0.045
accuracy: 0.274 
Score: 0.242 
learning_rate:  [6.680553237501894e-06]
learning_rate:  [6.680553237501894e-06]
mean Acc per epoch 0.28343173671130345
Epoch 36/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[37,    99] loss: 0.001 running loss:  0.044
accuracy: 0.290 
Score: 0.315 
learning_rate:  [6.4801366403768364e-06]
learning_rate:  [6.4801366403768364e-06]
mean Acc per epoch 0.2931215708081298
Epoch 37/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[38,    99] loss: 0.001 running loss:  0.044
accuracy: 0.286 
Score: 0.273 
learning_rate:  [6.285732541165531e-06]
learning_rate:  [6.285732541165531e-06]
mean Acc per epoch 0.2902355467498838
Epoch 38/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[39,    99] loss: 0.001 running loss:  0.043
accuracy: 0.295 
Score: 0.363 
learning_rate:  [6.097160564930565e-06]
learning_rate:  [6.097160564930565e-06]
mean Acc per epoch 0.30027002771410033
Epoch 39/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[40,    99] loss: 0.001 running loss:  0.043
accuracy: 0.308 
Score: 0.223 
learning_rate:  [5.914245747982648e-06]
learning_rate:  [5.914245747982648e-06]
mean Acc per epoch 0.30996644392659833
Epoch 40/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[41,    99] loss: 0.001 running loss:  0.043
accuracy: 0.321 
Score: 0.307 
learning_rate:  [5.7368183755431685e-06]
learning_rate:  [5.7368183755431685e-06]
mean Acc per epoch 0.3113174129688171
Epoch 41/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[42,    99] loss: 0.001 running loss:  0.042
accuracy: 0.332 
Score: 0.181 
learning_rate:  [5.5647138242768735e-06]
learning_rate:  [5.5647138242768735e-06]
mean Acc per epoch 0.31455388799006184
Epoch 42/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[43,    99] loss: 0.001 running loss:  0.043
accuracy: 0.316 
Score: 0.098 
learning_rate:  [5.397772409548567e-06]
learning_rate:  [5.397772409548567e-06]
mean Acc per epoch 0.31862332939067695
Epoch 43/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[44,    99] loss: 0.001 running loss:  0.043
accuracy: 0.312 
Score: 0.223 
learning_rate:  [5.23583923726211e-06]
learning_rate:  [5.23583923726211e-06]
mean Acc per epoch 0.31393206165123183
Epoch 44/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[45,    99] loss: 0.001 running loss:  0.043
accuracy: 0.318 
Score: 0.294 
learning_rate:  [5.078764060144246e-06]
learning_rate:  [5.078764060144246e-06]
mean Acc per epoch 0.3190612893935291
Epoch 45/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[46,    99] loss: 0.001 running loss:  0.041
accuracy: 0.325 
Score: 0.370 
learning_rate:  [4.926401138339919e-06]
learning_rate:  [4.926401138339919e-06]
mean Acc per epoch 0.3221229530687674
Epoch 46/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[47,    99] loss: 0.001 running loss:  0.042
accuracy: 0.321 
Score: 0.467 
learning_rate:  [4.778609104189721e-06]
learning_rate:  [4.778609104189721e-06]
mean Acc per epoch 0.3284186824385681
Epoch 47/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[48,    99] loss: 0.001 running loss:  0.042
accuracy: 0.335 
Score: 0.343 
learning_rate:  [4.635250831064029e-06]
learning_rate:  [4.635250831064029e-06]
mean Acc per epoch 0.34008586119986534
Epoch 48/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[49,    99] loss: 0.001 running loss:  0.040
accuracy: 0.350 
Score: 0.330 
learning_rate:  [4.496193306132109e-06]
learning_rate:  [4.496193306132109e-06]
mean Acc per epoch 0.34687064282494295
Epoch 49/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[50,    99] loss: 0.001 running loss:  0.041
accuracy: 0.346 
Score: 0.352 
learning_rate:  [4.361307506948145e-06]
learning_rate:  [4.361307506948145e-06]
mean Acc per epoch 0.3473249032582952
