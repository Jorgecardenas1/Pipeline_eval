cuda:0
Predictor_RESNET(
  (l1): Linear(in_features=768, out_features=196608, bias=False)
  (model): ResNet(
    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=False)
      (1): Linear(in_features=2048, out_features=1000, bias=False)
      (2): Linear(in_features=1000, out_features=1000, bias=False)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=1000, out_features=1, bias=False)
    )
  )
  (linear): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=False)
    (1): Linear(in_features=2048, out_features=1000, bias=False)
    (2): Linear(in_features=1000, out_features=1000, bias=False)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1000, out_features=1, bias=False)
  )
)
Epoch 0/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[1,    99] loss: 0.001 running loss:  0.065
accuracy: -0.042 
Score: 0.263 
learning_rate:  [1.8e-05]
learning_rate:  [1.8e-05]
mean Acc per epoch -0.010872874499334098
Epoch 1/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[2,    99] loss: 0.001 running loss:  0.056
accuracy: 0.085 
Score: 0.176 
learning_rate:  [1.62e-05]
learning_rate:  [1.62e-05]
mean Acc per epoch 0.09161008612056157
Epoch 2/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[3,    99] loss: 0.001 running loss:  0.054
accuracy: 0.139 
Score: 0.176 
learning_rate:  [1.4580000000000001e-05]
learning_rate:  [1.4580000000000001e-05]
mean Acc per epoch 0.13550137339655274
Epoch 3/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[4,    99] loss: 0.001 running loss:  0.052
accuracy: 0.174 
Score: 0.155 
learning_rate:  [1.3122e-05]
learning_rate:  [1.3122e-05]
mean Acc per epoch 0.1749200298991168
Epoch 4/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[5,    99] loss: 0.001 running loss:  0.051
accuracy: 0.184 
Score: 0.222 
learning_rate:  [1.1809800000000002e-05]
learning_rate:  [1.1809800000000002e-05]
mean Acc per epoch 0.18539359152281643
Epoch 5/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[6,    99] loss: 0.001 running loss:  0.047
accuracy: 0.227 
Score: 0.204 
learning_rate:  [1.0628820000000002e-05]
learning_rate:  [1.0628820000000002e-05]
mean Acc per epoch 0.21943097653613272
Epoch 6/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[7,    99] loss: 0.001 running loss:  0.049
accuracy: 0.214 
Score: 0.326 
learning_rate:  [9.565938000000002e-06]
learning_rate:  [9.565938000000002e-06]
mean Acc per epoch 0.21377504924361065
Epoch 7/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[8,    99] loss: 0.001 running loss:  0.047
accuracy: 0.244 
Score: 0.277 
learning_rate:  [8.609344200000001e-06]
learning_rate:  [8.609344200000001e-06]
mean Acc per epoch 0.245037044406154
Epoch 8/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[9,    99] loss: 0.001 running loss:  0.046
accuracy: 0.277 
Score: 0.278 
learning_rate:  [7.748409780000001e-06]
learning_rate:  [7.748409780000001e-06]
mean Acc per epoch 0.2698134915752102
Epoch 9/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[10,    99] loss: 0.001 running loss:  0.045
accuracy: 0.294 
Score: 0.293 
learning_rate:  [6.973568802000001e-06]
learning_rate:  [6.973568802000001e-06]
mean Acc per epoch 0.28426486465347045
Epoch 10/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[11,    99] loss: 0.001 running loss:  0.043
accuracy: 0.298 
Score: 0.299 
learning_rate:  [6.276211921800001e-06]
learning_rate:  [6.276211921800001e-06]
mean Acc per epoch 0.29971110341901047
Epoch 11/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[12,    99] loss: 0.001 running loss:  0.044
accuracy: 0.317 
Score: 0.416 
learning_rate:  [5.648590729620001e-06]
learning_rate:  [5.648590729620001e-06]
mean Acc per epoch 0.32180723821514573
Epoch 12/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[13,    99] loss: 0.001 running loss:  0.040
accuracy: 0.356 
Score: 0.360 
learning_rate:  [5.083731656658001e-06]
learning_rate:  [5.083731656658001e-06]
mean Acc per epoch 0.35120186345564003
Epoch 13/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[14,    99] loss: 0.001 running loss:  0.040
accuracy: 0.363 
Score: 0.265 
learning_rate:  [4.575358490992201e-06]
learning_rate:  [4.575358490992201e-06]
mean Acc per epoch 0.3559250572887616
Epoch 14/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[15,    99] loss: 0.001 running loss:  0.040
accuracy: 0.353 
Score: 0.127 
learning_rate:  [4.117822641892981e-06]
learning_rate:  [4.117822641892981e-06]
mean Acc per epoch 0.3602348860653142
Epoch 15/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[16,    99] loss: 0.000 running loss:  0.039
accuracy: 0.374 
Score: 0.354 
learning_rate:  [3.706040377703683e-06]
learning_rate:  [3.706040377703683e-06]
mean Acc per epoch 0.37698169928568365
Epoch 16/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[17,    99] loss: 0.001 running loss:  0.037
accuracy: 0.400 
Score: 0.466 
learning_rate:  [3.3354363399333148e-06]
learning_rate:  [3.3354363399333148e-06]
mean Acc per epoch 0.4009029077917788
Epoch 17/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[18,    99] loss: 0.000 running loss:  0.038
accuracy: 0.382 
Score: 0.549 
learning_rate:  [3.0018927059399835e-06]
learning_rate:  [3.0018927059399835e-06]
mean Acc per epoch 0.3934854920261997
Epoch 18/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[19,    99] loss: 0.001 running loss:  0.037
accuracy: 0.408 
Score: 0.492 
learning_rate:  [2.701703435345985e-06]
learning_rate:  [2.701703435345985e-06]
mean Acc per epoch 0.4116829620370942
Epoch 19/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[20,    99] loss: 0.001 running loss:  0.036
accuracy: 0.424 
Score: 0.426 
learning_rate:  [2.4315330918113866e-06]
learning_rate:  [2.4315330918113866e-06]
mean Acc per epoch 0.4207364228589866
Epoch 20/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[21,    99] loss: 0.001 running loss:  0.035
accuracy: 0.428 
Score: 0.439 
learning_rate:  [2.1883797826302482e-06]
learning_rate:  [2.1883797826302482e-06]
mean Acc per epoch 0.4321277274988844
Epoch 21/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[22,    99] loss: 0.000 running loss:  0.033
accuracy: 0.461 
Score: 0.612 
learning_rate:  [1.9695418043672235e-06]
learning_rate:  [1.9695418043672235e-06]
mean Acc per epoch 0.4510362352003124
Epoch 22/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[23,    99] loss: 0.000 running loss:  0.034
accuracy: 0.469 
Score: 0.486 
learning_rate:  [1.7725876239305011e-06]
learning_rate:  [1.7725876239305011e-06]
mean Acc per epoch 0.45652381673532827
Epoch 23/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[24,    99] loss: 0.000 running loss:  0.034
accuracy: 0.467 
Score: 0.615 
learning_rate:  [1.595328861537451e-06]
learning_rate:  [1.595328861537451e-06]
mean Acc per epoch 0.45273820839786216
Epoch 24/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[25,    99] loss: 0.000 running loss:  0.032
accuracy: 0.490 
Score: 0.476 
learning_rate:  [1.435795975383706e-06]
learning_rate:  [1.435795975383706e-06]
mean Acc per epoch 0.47579554604756835
Epoch 25/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[26,    99] loss: 0.000 running loss:  0.031
accuracy: 0.500 
Score: 0.603 
learning_rate:  [1.2922163778453354e-06]
learning_rate:  [1.2922163778453354e-06]
mean Acc per epoch 0.47801924679681773
Epoch 26/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[27,    99] loss: 0.000 running loss:  0.031
accuracy: 0.493 
Score: 0.495 
learning_rate:  [1.1629947400608018e-06]
learning_rate:  [1.1629947400608018e-06]
mean Acc per epoch 0.49389672588897837
Epoch 27/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[28,    99] loss: 0.000 running loss:  0.032
accuracy: 0.495 
Score: 0.546 
learning_rate:  [1.0466952660547218e-06]
learning_rate:  [1.0466952660547218e-06]
mean Acc per epoch 0.49126370573320033
Epoch 28/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[29,    99] loss: 0.000 running loss:  0.029
accuracy: 0.516 
Score: 0.615 
learning_rate:  [9.420257394492496e-07]
learning_rate:  [9.420257394492496e-07]
mean Acc per epoch 0.5044616386907727
Epoch 29/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[30,    99] loss: 0.000 running loss:  0.029
accuracy: 0.519 
Score: 0.592 
learning_rate:  [8.478231655043246e-07]
learning_rate:  [8.478231655043246e-07]
mean Acc per epoch 0.5161717646957171
Epoch 30/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[31,    99] loss: 0.001 running loss:  0.029
accuracy: 0.531 
Score: 0.472 
learning_rate:  [7.630408489538922e-07]
learning_rate:  [7.630408489538922e-07]
mean Acc per epoch 0.5202598550286571
Epoch 31/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[32,    99] loss: 0.000 running loss:  0.029
accuracy: 0.540 
Score: 0.252 
learning_rate:  [6.86736764058503e-07]
learning_rate:  [6.86736764058503e-07]
mean Acc per epoch 0.5338700562493368
Epoch 32/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[33,    99] loss: 0.000 running loss:  0.028
accuracy: 0.553 
Score: 0.495 
learning_rate:  [6.180630876526526e-07]
learning_rate:  [6.180630876526526e-07]
mean Acc per epoch 0.5426498985242847
Epoch 33/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[34,    99] loss: 0.001 running loss:  0.027
accuracy: 0.561 
Score: 0.537 
learning_rate:  [5.562567788873874e-07]
learning_rate:  [5.562567788873874e-07]
mean Acc per epoch 0.5546931902837624
Epoch 34/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[35,    99] loss: 0.000 running loss:  0.026
accuracy: 0.576 
Score: 0.505 
learning_rate:  [5.006311009986486e-07]
learning_rate:  [5.006311009986486e-07]
mean Acc per epoch 0.5602521139278955
Epoch 35/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[36,    99] loss: 0.001 running loss:  0.027
accuracy: 0.574 
Score: 0.485 
learning_rate:  [4.505679908987838e-07]
learning_rate:  [4.505679908987838e-07]
mean Acc per epoch 0.5665989595841842
Epoch 36/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[37,    99] loss: 0.000 running loss:  0.026
accuracy: 0.583 
Score: 0.622 
learning_rate:  [4.055111918089054e-07]
learning_rate:  [4.055111918089054e-07]
mean Acc per epoch 0.5738704029290188
Epoch 37/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[38,    99] loss: 0.000 running loss:  0.025
accuracy: 0.591 
Score: 0.795 
learning_rate:  [3.649600726280149e-07]
learning_rate:  [3.649600726280149e-07]
mean Acc per epoch 0.5894894277243
Epoch 38/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[39,    99] loss: 0.000 running loss:  0.025
accuracy: 0.597 
Score: 0.585 
learning_rate:  [3.2846406536521344e-07]
learning_rate:  [3.2846406536521344e-07]
mean Acc per epoch 0.5980561536838868
Epoch 39/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[40,    99] loss: 0.000 running loss:  0.024
accuracy: 0.610 
Score: 0.703 
learning_rate:  [2.956176588286921e-07]
learning_rate:  [2.956176588286921e-07]
mean Acc per epoch 0.6061641567557337
Epoch 40/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[41,    99] loss: 0.000 running loss:  0.024
accuracy: 0.620 
Score: 0.444 
learning_rate:  [2.660558929458229e-07]
learning_rate:  [2.660558929458229e-07]
mean Acc per epoch 0.6199493317688792
Epoch 41/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[42,    99] loss: 0.000 running loss:  0.024
accuracy: 0.626 
Score: 0.538 
learning_rate:  [2.394503036512406e-07]
learning_rate:  [2.394503036512406e-07]
mean Acc per epoch 0.6300748916190473
Epoch 42/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[43,    99] loss: 0.000 running loss:  0.022
accuracy: 0.654 
Score: 0.729 
learning_rate:  [2.1550527328611657e-07]
learning_rate:  [2.1550527328611657e-07]
mean Acc per epoch 0.6326173935916883
Epoch 43/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[44,    99] loss: 0.000 running loss:  0.022
accuracy: 0.633 
Score: 0.525 
learning_rate:  [1.939547459575049e-07]
learning_rate:  [1.939547459575049e-07]
mean Acc per epoch 0.6369380877071708
Epoch 44/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[45,    99] loss: 0.000 running loss:  0.021
accuracy: 0.661 
Score: 0.694 
learning_rate:  [1.7455927136175443e-07]
learning_rate:  [1.7455927136175443e-07]
mean Acc per epoch 0.6522451934475628
Epoch 45/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[46,    99] loss: 0.000 running loss:  0.020
accuracy: 0.666 
Score: 0.687 
learning_rate:  [1.5710334422557899e-07]
learning_rate:  [1.5710334422557899e-07]
mean Acc per epoch 0.6642527132884253
Epoch 46/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[47,    99] loss: 0.000 running loss:  0.020
accuracy: 0.664 
Score: 0.680 
learning_rate:  [1.413930098030211e-07]
learning_rate:  [1.413930098030211e-07]
mean Acc per epoch 0.6652084849036018
Epoch 47/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[48,    99] loss: 0.000 running loss:  0.019
accuracy: 0.686 
Score: 0.745 
learning_rate:  [1.2725370882271898e-07]
learning_rate:  [1.2725370882271898e-07]
mean Acc per epoch 0.6738908586227323
Epoch 48/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[49,    99] loss: 0.001 running loss:  0.020
accuracy: 0.687 
Score: 0.443 
learning_rate:  [1.1452833794044709e-07]
learning_rate:  [1.1452833794044709e-07]
mean Acc per epoch 0.6813169626014905
Epoch 49/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[50,    99] loss: 0.000 running loss:  0.019
accuracy: 0.689 
Score: 0.624 
learning_rate:  [1.0307550414640238e-07]
learning_rate:  [1.0307550414640238e-07]
mean Acc per epoch 0.6854537761050428
