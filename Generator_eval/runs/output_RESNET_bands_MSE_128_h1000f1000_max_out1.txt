cuda:0
Predictor_RESNET(
  (l1): Linear(in_features=768, out_features=49152, bias=False)
  (model): ResNet(
    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=False)
      (1): Linear(in_features=2048, out_features=1000, bias=False)
      (2): Linear(in_features=1000, out_features=1000, bias=False)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=1000, out_features=1, bias=False)
    )
  )
  (linear): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=False)
    (1): Linear(in_features=2048, out_features=1000, bias=False)
    (2): Linear(in_features=1000, out_features=1000, bias=False)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1000, out_features=1, bias=False)
  )
)
Epoch 0/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[1,    99] loss: 0.001 running loss:  0.066
accuracy: -0.066 
Score: -0.644 
learning_rate:  [1.8e-05]
learning_rate:  [1.8e-05]
mean Acc per epoch -0.038331937739719865
Epoch 1/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[2,    99] loss: 0.001 running loss:  0.056
accuracy: 0.112 
Score: 0.225 
learning_rate:  [1.62e-05]
learning_rate:  [1.62e-05]
mean Acc per epoch 0.11023905980571197
Epoch 2/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[3,    99] loss: 0.001 running loss:  0.056
accuracy: 0.101 
Score: 0.126 
learning_rate:  [1.4580000000000001e-05]
learning_rate:  [1.4580000000000001e-05]
mean Acc per epoch 0.11276463441218616
Epoch 3/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[4,    99] loss: 0.001 running loss:  0.053
accuracy: 0.155 
Score: 0.156 
learning_rate:  [1.3122e-05]
learning_rate:  [1.3122e-05]
mean Acc per epoch 0.16308559873225908
Epoch 4/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[5,    99] loss: 0.001 running loss:  0.051
accuracy: 0.191 
Score: 0.253 
learning_rate:  [1.1809800000000002e-05]
learning_rate:  [1.1809800000000002e-05]
mean Acc per epoch 0.18300665968696986
Epoch 5/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[6,    99] loss: 0.001 running loss:  0.050
accuracy: 0.212 
Score: 0.263 
learning_rate:  [1.0628820000000002e-05]
learning_rate:  [1.0628820000000002e-05]
mean Acc per epoch 0.2024830963509394
Epoch 6/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[7,    99] loss: 0.001 running loss:  0.050
accuracy: 0.204 
Score: 0.292 
learning_rate:  [9.565938000000002e-06]
learning_rate:  [9.565938000000002e-06]
mean Acc per epoch 0.2097683167230742
Epoch 7/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[8,    99] loss: 0.001 running loss:  0.048
accuracy: 0.201 
Score: 0.424 
learning_rate:  [8.609344200000001e-06]
learning_rate:  [8.609344200000001e-06]
mean Acc per epoch 0.21417012922331655
Epoch 8/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[9,    99] loss: 0.001 running loss:  0.047
accuracy: 0.237 
Score: 0.088 
learning_rate:  [7.748409780000001e-06]
learning_rate:  [7.748409780000001e-06]
mean Acc per epoch 0.2366810828871632
Epoch 9/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[10,    99] loss: 0.001 running loss:  0.047
accuracy: 0.248 
Score: 0.195 
learning_rate:  [6.973568802000001e-06]
learning_rate:  [6.973568802000001e-06]
mean Acc per epoch 0.2504677970755625
Epoch 10/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[11,    99] loss: 0.001 running loss:  0.045
accuracy: 0.276 
Score: 0.301 
learning_rate:  [6.276211921800001e-06]
learning_rate:  [6.276211921800001e-06]
mean Acc per epoch 0.27614898432393736
Epoch 11/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[12,    99] loss: 0.001 running loss:  0.045
accuracy: 0.273 
Score: 0.195 
learning_rate:  [5.648590729620001e-06]
learning_rate:  [5.648590729620001e-06]
mean Acc per epoch 0.27818788031204866
Epoch 12/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[13,    99] loss: 0.001 running loss:  0.043
accuracy: 0.314 
Score: 0.304 
learning_rate:  [5.083731656658001e-06]
learning_rate:  [5.083731656658001e-06]
mean Acc per epoch 0.30034731511708374
Epoch 13/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[14,    99] loss: 0.001 running loss:  0.043
accuracy: 0.307 
Score: -0.058 
learning_rate:  [4.575358490992201e-06]
learning_rate:  [4.575358490992201e-06]
mean Acc per epoch 0.31558432537699554
Epoch 14/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[15,    99] loss: 0.001 running loss:  0.042
accuracy: 0.328 
Score: 0.283 
learning_rate:  [4.117822641892981e-06]
learning_rate:  [4.117822641892981e-06]
mean Acc per epoch 0.3236551685300834
Epoch 15/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[16,    99] loss: 0.001 running loss:  0.042
accuracy: 0.333 
Score: 0.380 
learning_rate:  [3.706040377703683e-06]
learning_rate:  [3.706040377703683e-06]
mean Acc per epoch 0.3387374549726524
Epoch 16/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[17,    99] loss: 0.001 running loss:  0.040
accuracy: 0.362 
Score: 0.160 
learning_rate:  [3.3354363399333148e-06]
learning_rate:  [3.3354363399333148e-06]
mean Acc per epoch 0.35211451425194673
Epoch 17/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[18,    99] loss: 0.001 running loss:  0.039
accuracy: 0.366 
Score: 0.261 
learning_rate:  [3.0018927059399835e-06]
learning_rate:  [3.0018927059399835e-06]
mean Acc per epoch 0.3550674690856312
Epoch 18/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[19,    99] loss: 0.001 running loss:  0.039
accuracy: 0.364 
Score: 0.106 
learning_rate:  [2.701703435345985e-06]
learning_rate:  [2.701703435345985e-06]
mean Acc per epoch 0.36990158956599684
Epoch 19/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[20,    99] loss: 0.001 running loss:  0.038
accuracy: 0.399 
Score: 0.493 
learning_rate:  [2.4315330918113866e-06]
learning_rate:  [2.4315330918113866e-06]
mean Acc per epoch 0.3795822387191338
Epoch 20/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[21,    99] loss: 0.001 running loss:  0.037
accuracy: 0.397 
Score: 0.414 
learning_rate:  [2.1883797826302482e-06]
learning_rate:  [2.1883797826302482e-06]
mean Acc per epoch 0.39868931237836297
Epoch 21/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[22,    99] loss: 0.001 running loss:  0.037
accuracy: 0.407 
Score: 0.168 
learning_rate:  [1.9695418043672235e-06]
learning_rate:  [1.9695418043672235e-06]
mean Acc per epoch 0.4081366133830043
Epoch 22/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[23,    99] loss: 0.001 running loss:  0.036
accuracy: 0.417 
Score: 0.483 
learning_rate:  [1.7725876239305011e-06]
learning_rate:  [1.7725876239305011e-06]
mean Acc per epoch 0.40813809658290034
Epoch 23/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[24,    99] loss: 0.001 running loss:  0.036
accuracy: 0.409 
Score: 0.331 
learning_rate:  [1.595328861537451e-06]
learning_rate:  [1.595328861537451e-06]
mean Acc per epoch 0.4166252168370787
Epoch 24/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[25,    99] loss: 0.000 running loss:  0.035
accuracy: 0.444 
Score: 0.543 
learning_rate:  [1.435795975383706e-06]
learning_rate:  [1.435795975383706e-06]
mean Acc per epoch 0.42932214078921066
Epoch 25/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[26,    99] loss: 0.001 running loss:  0.034
accuracy: 0.451 
Score: 0.388 
learning_rate:  [1.2922163778453354e-06]
learning_rate:  [1.2922163778453354e-06]
mean Acc per epoch 0.4407433199953782
Epoch 26/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[27,    99] loss: 0.001 running loss:  0.034
accuracy: 0.453 
Score: 0.308 
learning_rate:  [1.1629947400608018e-06]
learning_rate:  [1.1629947400608018e-06]
mean Acc per epoch 0.4538344476376997
Epoch 27/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[28,    99] loss: 0.001 running loss:  0.033
accuracy: 0.466 
Score: 0.376 
learning_rate:  [1.0466952660547218e-06]
learning_rate:  [1.0466952660547218e-06]
mean Acc per epoch 0.45728476984894645
Epoch 28/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[29,    99] loss: 0.000 running loss:  0.033
accuracy: 0.468 
Score: 0.444 
learning_rate:  [9.420257394492496e-07]
learning_rate:  [9.420257394492496e-07]
mean Acc per epoch 0.46968725026713587
Epoch 29/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[30,    99] loss: 0.000 running loss:  0.032
accuracy: 0.488 
Score: 0.650 
learning_rate:  [8.478231655043246e-07]
learning_rate:  [8.478231655043246e-07]
mean Acc per epoch 0.47686866178875303
Epoch 30/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[31,    99] loss: 0.000 running loss:  0.032
accuracy: 0.487 
Score: 0.512 
learning_rate:  [7.630408489538922e-07]
learning_rate:  [7.630408489538922e-07]
mean Acc per epoch 0.4852365425412642
Epoch 31/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[32,    99] loss: 0.000 running loss:  0.031
accuracy: 0.489 
Score: 0.555 
learning_rate:  [6.86736764058503e-07]
learning_rate:  [6.86736764058503e-07]
mean Acc per epoch 0.4960837239969677
Epoch 32/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[33,    99] loss: 0.001 running loss:  0.031
accuracy: 0.507 
Score: 0.315 
learning_rate:  [6.180630876526526e-07]
learning_rate:  [6.180630876526526e-07]
mean Acc per epoch 0.5072111805848805
Epoch 33/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[34,    99] loss: 0.000 running loss:  0.030
accuracy: 0.530 
Score: 0.580 
learning_rate:  [5.562567788873874e-07]
learning_rate:  [5.562567788873874e-07]
mean Acc per epoch 0.5194014189870917
Epoch 34/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[35,    99] loss: 0.001 running loss:  0.030
accuracy: 0.516 
Score: 0.400 
learning_rate:  [5.006311009986486e-07]
learning_rate:  [5.006311009986486e-07]
mean Acc per epoch 0.52233105078002
Epoch 35/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[36,    99] loss: 0.000 running loss:  0.029
accuracy: 0.531 
Score: 0.505 
learning_rate:  [4.505679908987838e-07]
learning_rate:  [4.505679908987838e-07]
mean Acc per epoch 0.5302969015995647
Epoch 36/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[37,    99] loss: 0.000 running loss:  0.028
accuracy: 0.545 
Score: 0.509 
learning_rate:  [4.055111918089054e-07]
learning_rate:  [4.055111918089054e-07]
mean Acc per epoch 0.5424089998798448
Epoch 37/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[38,    99] loss: 0.001 running loss:  0.027
accuracy: 0.566 
Score: 0.482 
learning_rate:  [3.649600726280149e-07]
learning_rate:  [3.649600726280149e-07]
mean Acc per epoch 0.555144073520501
Epoch 38/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[39,    99] loss: 0.000 running loss:  0.027
accuracy: 0.566 
Score: 0.579 
learning_rate:  [3.2846406536521344e-07]
learning_rate:  [3.2846406536521344e-07]
mean Acc per epoch 0.5569923595810138
Epoch 39/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[40,    99] loss: 0.000 running loss:  0.026
accuracy: 0.586 
Score: 0.598 
learning_rate:  [2.956176588286921e-07]
learning_rate:  [2.956176588286921e-07]
mean Acc per epoch 0.5704296450301478
Epoch 40/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[41,    99] loss: 0.000 running loss:  0.026
accuracy: 0.585 
Score: 0.623 
learning_rate:  [2.660558929458229e-07]
learning_rate:  [2.660558929458229e-07]
mean Acc per epoch 0.576082396605074
Epoch 41/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[42,    99] loss: 0.000 running loss:  0.026
accuracy: 0.581 
Score: 0.435 
learning_rate:  [2.394503036512406e-07]
learning_rate:  [2.394503036512406e-07]
mean Acc per epoch 0.5781745434973771
Epoch 42/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[43,    99] loss: 0.000 running loss:  0.025
accuracy: 0.597 
Score: 0.456 
learning_rate:  [2.1550527328611657e-07]
learning_rate:  [2.1550527328611657e-07]
mean Acc per epoch 0.5957609495957696
Epoch 43/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[44,    99] loss: 0.000 running loss:  0.024
accuracy: 0.608 
Score: 0.671 
learning_rate:  [1.939547459575049e-07]
learning_rate:  [1.939547459575049e-07]
mean Acc per epoch 0.6020522177074934
Epoch 44/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[45,    99] loss: 0.000 running loss:  0.024
accuracy: 0.614 
Score: 0.562 
learning_rate:  [1.7455927136175443e-07]
learning_rate:  [1.7455927136175443e-07]
mean Acc per epoch 0.607478239718648
Epoch 45/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[46,    99] loss: 0.000 running loss:  0.024
accuracy: 0.619 
Score: 0.656 
learning_rate:  [1.5710334422557899e-07]
learning_rate:  [1.5710334422557899e-07]
mean Acc per epoch 0.6169697633976382
Epoch 46/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[47,    99] loss: 0.000 running loss:  0.023
accuracy: 0.636 
Score: 0.483 
learning_rate:  [1.413930098030211e-07]
learning_rate:  [1.413930098030211e-07]
mean Acc per epoch 0.6208844096679567
Epoch 47/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[48,    99] loss: 0.000 running loss:  0.023
accuracy: 0.621 
Score: 0.354 
learning_rate:  [1.2725370882271898e-07]
learning_rate:  [1.2725370882271898e-07]
mean Acc per epoch 0.6214718572182428
Epoch 48/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[49,    99] loss: 0.000 running loss:  0.022
accuracy: 0.645 
Score: 0.731 
learning_rate:  [1.1452833794044709e-07]
learning_rate:  [1.1452833794044709e-07]
mean Acc per epoch 0.630297752109291
Epoch 49/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[50,    99] loss: 0.000 running loss:  0.022
accuracy: 0.644 
Score: 0.760 
learning_rate:  [1.0307550414640238e-07]
learning_rate:  [1.0307550414640238e-07]
mean Acc per epoch 0.6373677757814615
