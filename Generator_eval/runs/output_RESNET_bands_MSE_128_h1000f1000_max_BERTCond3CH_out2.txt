cuda:0
Predictor_RESNET(
  (l1): Linear(in_features=768, out_features=49152, bias=False)
  (model): ResNet(
    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=False)
      (1): Linear(in_features=2048, out_features=1000, bias=False)
      (2): Linear(in_features=1000, out_features=1000, bias=False)
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=1000, out_features=2, bias=False)
    )
  )
  (linear): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=False)
    (1): Linear(in_features=2048, out_features=1000, bias=False)
    (2): Linear(in_features=1000, out_features=1000, bias=False)
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=1000, out_features=2, bias=False)
  )
)
Epoch 0/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[1,    99] loss: 0.060 running loss:  484.620
accuracy: -85.491 
Score: -13.627 
learning_rate:  [1.94e-05]
learning_rate:  [1.94e-05]
mean Acc per epoch -56.515496065465165
Epoch 1/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[2,    99] loss: 0.079 running loss:  5.211
accuracy: -15.019 
Score: -14.069 
learning_rate:  [1.8818e-05]
learning_rate:  [1.8818e-05]
mean Acc per epoch -14.432537324026583
Epoch 2/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[3,    99] loss: 0.072 running loss:  5.114
accuracy: -12.776 
Score: -7.745 
learning_rate:  [1.8253459999999998e-05]
learning_rate:  [1.8253459999999998e-05]
mean Acc per epoch -13.005146898979786
Epoch 3/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[4,    99] loss: 0.083 running loss:  4.858
accuracy: -12.008 
Score: -12.754 
learning_rate:  [1.77058562e-05]
learning_rate:  [1.77058562e-05]
mean Acc per epoch -11.875920439132493
Epoch 4/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[5,    99] loss: 0.064 running loss:  4.802
accuracy: -11.418 
Score: -10.078 
learning_rate:  [1.7174680513999998e-05]
learning_rate:  [1.7174680513999998e-05]
mean Acc per epoch -10.813831167607328
Epoch 5/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[6,    99] loss: 0.064 running loss:  4.760
accuracy: -10.067 
Score: -7.644 
learning_rate:  [1.6659440098579996e-05]
learning_rate:  [1.6659440098579996e-05]
mean Acc per epoch -9.859428310202638
Epoch 6/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[7,    99] loss: 0.050 running loss:  4.763
accuracy: -8.920 
Score: -9.095 
learning_rate:  [1.6159656895622596e-05]
learning_rate:  [1.6159656895622596e-05]
mean Acc per epoch -9.124761529274886
Epoch 7/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[8,    99] loss: 0.098 running loss:  4.654
accuracy: -8.836 
Score: -9.687 
learning_rate:  [1.5674867188753917e-05]
learning_rate:  [1.5674867188753917e-05]
mean Acc per epoch -8.694135604341971
Epoch 8/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[9,    99] loss: 0.051 running loss:  4.552
accuracy: -8.162 
Score: -6.090 
learning_rate:  [1.5204621173091299e-05]
learning_rate:  [1.5204621173091299e-05]
mean Acc per epoch -8.012928939866063
Epoch 9/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[10,    99] loss: 0.064 running loss:  4.596
accuracy: -7.979 
Score: -9.951 
learning_rate:  [1.474848253789856e-05]
learning_rate:  [1.474848253789856e-05]
mean Acc per epoch -7.70805794718425
Epoch 10/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[11,    99] loss: 0.064 running loss:  4.444
accuracy: -7.128 
Score: -8.550 
learning_rate:  [1.4306028061761602e-05]
learning_rate:  [1.4306028061761602e-05]
mean Acc per epoch -6.836848705940219
Epoch 11/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[12,    99] loss: 0.079 running loss:  4.518
accuracy: -6.991 
Score: -6.305 
learning_rate:  [1.3876847219908753e-05]
learning_rate:  [1.3876847219908753e-05]
mean Acc per epoch -6.864950996298109
Epoch 12/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[13,    99] loss: 0.061 running loss:  4.372
accuracy: -6.451 
Score: -7.294 
learning_rate:  [1.346054180331149e-05]
learning_rate:  [1.346054180331149e-05]
mean Acc per epoch -6.297453520029377
Epoch 13/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[14,    99] loss: 0.058 running loss:  4.324
accuracy: -5.983 
Score: -6.732 
learning_rate:  [1.3056725549212145e-05]
learning_rate:  [1.3056725549212145e-05]
mean Acc per epoch -5.986873536031616
Epoch 14/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[15,    99] loss: 0.060 running loss:  4.374
accuracy: -5.736 
Score: -4.623 
learning_rate:  [1.266502378273578e-05]
learning_rate:  [1.266502378273578e-05]
mean Acc per epoch -5.654617154217115
Epoch 15/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[16,    99] loss: 0.061 running loss:  4.212
accuracy: -5.673 
Score: -4.386 
learning_rate:  [1.2285073069253707e-05]
learning_rate:  [1.2285073069253707e-05]
mean Acc per epoch -5.592126869168579
Epoch 16/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[17,    99] loss: 0.060 running loss:  4.265
accuracy: -5.191 
Score: -4.985 
learning_rate:  [1.1916520877176095e-05]
learning_rate:  [1.1916520877176095e-05]
mean Acc per epoch -5.134810780415987
Epoch 17/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[18,    99] loss: 0.045 running loss:  4.094
accuracy: -5.253 
Score: -5.658 
learning_rate:  [1.1559025250860812e-05]
learning_rate:  [1.1559025250860812e-05]
mean Acc per epoch -5.080914366689201
Epoch 18/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[19,    99] loss: 0.077 running loss:  4.193
accuracy: -5.066 
Score: -5.932 
learning_rate:  [1.1212254493334987e-05]
learning_rate:  [1.1212254493334987e-05]
mean Acc per epoch -4.908027247449725
Epoch 19/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[20,    99] loss: 0.063 running loss:  4.321
accuracy: -4.712 
Score: -6.973 
learning_rate:  [1.0875886858534937e-05]
learning_rate:  [1.0875886858534937e-05]
mean Acc per epoch -4.741119827966094
Epoch 20/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[21,    99] loss: 0.063 running loss:  4.152
accuracy: -4.641 
Score: -4.341 
learning_rate:  [1.0549610252778888e-05]
learning_rate:  [1.0549610252778888e-05]
mean Acc per epoch -4.520494237334937
Epoch 21/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[22,    99] loss: 0.050 running loss:  4.176
accuracy: -4.453 
Score: -3.296 
learning_rate:  [1.023312194519552e-05]
learning_rate:  [1.023312194519552e-05]
mean Acc per epoch -4.605158630979707
Epoch 22/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[23,    99] loss: 0.052 running loss:  4.058
accuracy: -4.393 
Score: -3.085 
learning_rate:  [9.926128286839655e-06]
learning_rate:  [9.926128286839655e-06]
mean Acc per epoch -4.290046431281997
Epoch 23/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[24,    99] loss: 0.057 running loss:  4.065
accuracy: -4.203 
Score: -3.367 
learning_rate:  [9.628344438234465e-06]
learning_rate:  [9.628344438234465e-06]
mean Acc per epoch -4.281230903175207
Epoch 24/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[25,    99] loss: 0.074 running loss:  4.111
accuracy: -4.409 
Score: -2.685 
learning_rate:  [9.33949410508743e-06]
learning_rate:  [9.33949410508743e-06]
mean Acc per epoch -4.242180828909071
Epoch 25/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[26,    99] loss: 0.060 running loss:  4.036
accuracy: -4.000 
Score: -2.576 
learning_rate:  [9.059309281934807e-06]
learning_rate:  [9.059309281934807e-06]
mean Acc per epoch -4.062803710581524
Epoch 26/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[27,    99] loss: 0.055 running loss:  3.945
accuracy: -4.034 
Score: -5.362 
learning_rate:  [8.787530003476762e-06]
learning_rate:  [8.787530003476762e-06]
mean Acc per epoch -3.9050051155401313
Epoch 27/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[28,    99] loss: 0.048 running loss:  3.907
accuracy: -3.896 
Score: -3.804 
learning_rate:  [8.523904103372459e-06]
learning_rate:  [8.523904103372459e-06]
mean Acc per epoch -3.8905198582044624
Epoch 28/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[29,    99] loss: 0.054 running loss:  3.991
accuracy: -3.872 
Score: -4.508 
learning_rate:  [8.268186980271286e-06]
learning_rate:  [8.268186980271286e-06]
mean Acc per epoch -3.861974961859572
Epoch 29/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[30,    99] loss: 0.053 running loss:  3.845
accuracy: -3.778 
Score: -4.147 
learning_rate:  [8.020141370863147e-06]
learning_rate:  [8.020141370863147e-06]
mean Acc per epoch -3.746509643593694
Epoch 30/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[31,    99] loss: 0.058 running loss:  3.878
accuracy: -3.585 
Score: -3.458 
learning_rate:  [7.779537129737253e-06]
learning_rate:  [7.779537129737253e-06]
mean Acc per epoch -3.539742447754877
Epoch 31/49
----------
  0%|          | 0/169 [00:00<?, ?it/s]
[32,    99] loss: 0.066 running loss:  3.830
accuracy: -3.450 
Score: -3.029 
learning_rate:  [7.546151015845135e-06]
