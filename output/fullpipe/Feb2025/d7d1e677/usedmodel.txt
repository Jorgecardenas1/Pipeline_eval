batch:GAN Training
fitness:0.002124712197212569
Predicte:tensor([[-2.7892e-02, -5.6432e-03,  1.1505e-02,  5.0642e-04, -8.4898e-03,
         -2.4479e-02, -3.1977e-02, -2.7417e-02, -2.6756e-02, -7.7630e-03,
          7.2670e-03,  2.8515e-02,  5.6596e-02,  9.3878e-02,  1.2701e-01,
          1.5657e-01,  1.7921e-01,  1.9559e-01,  2.0329e-01,  2.4208e-01,
          3.0328e-01,  3.8280e-01,  4.7385e-01,  5.4885e-01,  5.9408e-01,
          6.0027e-01,  5.6473e-01,  4.8162e-01,  3.6506e-01,  2.7876e-01,
          2.1378e-01,  1.7131e-01,  9.6115e-02,  4.1348e-02,  7.6300e-03,
         -2.9737e-03, -1.1259e-02, -2.6330e-03,  1.7067e-02,  3.3027e-02,
          4.8058e-02,  5.4948e-02,  7.8053e-02,  6.8503e-02,  2.4340e-02,
          2.4604e-02,  2.4896e-02,  3.9007e-02,  6.7572e-02,  5.9360e-02,
          5.8509e-02,  6.1231e-02,  6.4207e-02,  3.8341e-02,  4.2730e-02,
          6.6657e-02,  9.3006e-02,  8.7098e-02,  5.1063e-02,  5.1697e-02,
          3.2643e-02,  4.1903e-02,  3.7847e-02,  4.0628e-02,  5.5995e-02,
          5.0451e-02,  4.7797e-02,  4.0592e-02,  1.0115e-02, -1.9555e-02,
         -2.0574e-02, -9.5038e-03,  4.0438e-02,  5.0682e-02,  3.5328e-02,
          3.3837e-02,  3.7502e-02,  3.6782e-02,  4.3508e-02,  4.1371e-02,
          6.0442e-02,  6.9745e-02,  7.0261e-02,  9.0559e-02,  1.0098e-01,
          1.1019e-01,  1.0838e-01,  8.7749e-02,  6.7213e-02,  4.8831e-02,
          3.3774e-02,  3.2105e-02,  3.5316e-02,  1.9942e-02,  2.3287e-02,
          1.0746e-02,  9.7243e-03, -7.2862e-03, -5.8263e-03, -1.4356e-02]],
       device='cuda:0', grad_fn=<TanhBackward0>)
latent:[ 0.028  0.041  0.977  0.011  0.282  0.843  0.085  0.014  0.012 -0.
  0.893  0.186  0.08   0.115  0.776  0.141  0.881  0.999  0.312  0.98
  0.947  0.052  1.     0.953  0.74   0.939  0.04   0.039  0.025  0.873
  0.246  0.095  0.033  0.888  0.971  0.945  0.941  0.207  0.866  0.036
  0.503  0.359  0.082  0.082  0.943  0.876  0.944  0.072  0.843  0.926
  0.027  0.853  0.081  0.952  0.706  0.96   0.195  0.171  0.948  0.015
  0.056  0.647  0.99   0.334  0.018  0.003  0.974  0.986  0.851  0.598
  0.861  0.182  0.951  0.116  0.152  0.874  0.059  0.98   0.079  0.062
  0.772  0.991  0.664  0.031  0.916  0.641  0.049  0.545  0.006  0.971
  0.073  0.97   0.891  0.029  0.99   0.48   0.017  0.229  0.188  1.
  0.022  0.955  0.029  0.856  0.005  0.183  0.357  0.742  0.081  0.046
  0.051  0.991  0.047 -0.     0.821  0.065  0.94   0.995  0.903  0.976
  0.126  0.79   0.818  0.135  0.589  0.152  0.949  0.718  0.577  0.952
  0.957  0.895  0.417  0.342  0.706  0.923  0.961  0.115  0.996  0.989
  0.168  0.018  0.117  0.126  0.976  0.938  0.737  0.148  0.939  0.058
  0.198  0.984  0.134  0.055  0.025  0.058  0.995  0.713  0.951  0.125
  0.798  0.941  0.934  0.57   0.112  0.944  0.093  0.951  0.825  0.946
  0.976  0.525  0.022  0.081  0.056  0.659  0.993  0.595  0.061  0.021
  0.034  0.681  0.939  0.334  0.054  0.026  0.95   0.912  0.118  0.042
  0.923  0.252  0.988  0.942  0.989  0.972  0.029  0.052  0.952  0.258
  0.227  0.871  0.761  0.366  0.253  0.12   0.037  0.55   0.986  0.631
  0.245  0.178  0.891  0.964  0.652  0.501  0.697  0.917  0.523  0.117
  0.006  0.337  0.872  0.69   0.15   0.201  0.44   0.019  0.082  0.182
  1.     0.885  0.948  0.675  0.638  0.934  0.526  0.019  0.975  0.652
  0.912  0.692  0.914  0.025  0.914  0.007  0.936  0.253  0.874  0.984
  0.147  0.866  0.49   0.943  0.564  0.382  0.156  0.933  0.383  0.014
  0.713  0.022  0.119  0.937  0.24   0.841  0.235  0.198  0.984  0.87
  0.569  0.077  0.23   0.957  0.102  0.878  0.956  0.258  0.94   0.234
  0.142  0.956  0.041  0.924  0.156  0.434  0.155  0.897  0.518  0.525
  0.09   0.842  0.692  0.867  0.073  0.025  0.888  0.875  0.189  0.421
  0.882  0.016  0.094  0.959  0.111  0.75   0.988  0.956  0.78   0.668
  0.114  0.029  0.884  0.983  0.974  0.043  0.088  0.958  0.759  0.193
  0.107  0.52   0.18   0.396  0.099  0.985  0.096  0.841  0.186  0.822
  0.031  0.07   0.99   0.93   0.845  0.287  0.374  0.997  0.991  0.988
  0.277  0.508  0.865  0.989  0.019  0.037  0.699  0.984  0.63   0.001
  0.129  0.416  0.797  0.405  0.943  0.919  0.931  0.93   0.956  0.977
  0.798  0.035  0.534  0.099  0.01   0.471  0.984  0.061  0.211  0.034
  0.901  0.127  0.309  0.944  0.869  0.372  0.986  0.002  0.95   0.968
  0.289  0.969  0.849  0.257  0.985  0.175  0.112  0.45   0.943  0.637
  0.192  0.081  0.942  0.259  0.499  0.001  0.684  0.947  0.188  0.969]
Truth:[[7.50300000e+01 7.50600000e+01 7.50900000e+01 7.51200000e+01
  7.51500000e+01 7.51800000e+01 7.52100000e+01 7.52400000e+01
  7.52700000e+01 7.53000000e+01 7.53300000e+01 7.53600000e+01
  7.53900000e+01 7.54200000e+01 7.54500000e+01 7.54800000e+01
  7.55100000e+01 7.55400000e+01 7.55700000e+01 7.56000000e+01
  7.56300000e+01 7.56600000e+01 7.56900000e+01 7.57200000e+01
  7.57500000e+01 7.57800000e+01 7.58100000e+01 7.58400000e+01
  7.58700000e+01 7.59000000e+01 7.59300000e+01 7.59600000e+01
  7.59900000e+01 7.60200000e+01 7.60500000e+01 7.60800000e+01
  7.61100000e+01 7.61400000e+01 7.61700000e+01 7.62000000e+01
  7.62300000e+01 7.62600000e+01 7.62900000e+01 7.63200000e+01
  7.63500000e+01 7.63800000e+01 7.64100000e+01 7.64400000e+01
  7.64700000e+01 7.65000000e+01 7.65300000e+01 7.65600000e+01
  7.65900000e+01 7.66200000e+01 7.66500000e+01 7.66800000e+01
  7.67100000e+01 7.67400000e+01 7.67700000e+01 7.68000000e+01
  7.68300000e+01 7.68600000e+01 7.68900000e+01 7.69200000e+01
  7.69500000e+01 7.69800000e+01 7.70100000e+01 7.70400000e+01
  7.70700000e+01 7.71000000e+01 7.71300000e+01 7.71600000e+01
  7.71900000e+01 7.72200000e+01 7.72500000e+01 7.72800000e+01
  7.73100000e+01 7.73400000e+01 7.73700000e+01 7.74000000e+01
  7.74300000e+01 7.74600000e+01 7.74900000e+01 7.75200000e+01
  7.75500000e+01 7.75800000e+01 7.76100000e+01 7.76400000e+01
  7.76700000e+01 7.77000000e+01 7.77300000e+01 7.77600000e+01
  7.77900000e+01 7.78200000e+01 7.78500000e+01 7.78800000e+01
  7.79100000e+01 7.79400000e+01 7.79700000e+01 7.80000000e+01]
 [1.99516329e-02 2.13030573e-02 2.28215249e-02 2.45369178e-02
  2.64861787e-02 2.87154000e-02 3.12826645e-02 3.42619597e-02
  3.77486451e-02 4.18672040e-02 4.67824060e-02 5.27156420e-02
  5.99692262e-02 6.89631306e-02 8.02912925e-02 9.48087105e-02
  1.13765923e-01 1.39011257e-01 1.73269523e-01 2.20427752e-01
  2.85465979e-01 3.72898021e-01 4.81628702e-01 5.96330335e-01
  6.84190240e-01 7.06308310e-01 6.42794662e-01 5.20333356e-01
  3.91654793e-01 2.87857860e-01 2.12992652e-01 1.60753475e-01
  1.24190467e-01 9.81476925e-02 7.91861533e-02 6.50706753e-02
  5.43424819e-02 4.60342094e-02 3.94913044e-02 3.42614596e-02
  3.00256743e-02 2.65546044e-02 2.36804100e-02 2.12782419e-02
  1.92538345e-02 1.75350358e-02 1.60659267e-02 1.48026700e-02
  1.37105381e-02 1.27617522e-02 1.19338940e-02 1.12087214e-02
  1.05712772e-02 1.00092108e-02 9.51225617e-03 9.07182825e-03
  8.68070616e-03 8.33278403e-03 8.02287293e-03 7.74654248e-03
  7.49999327e-03 7.27995351e-03 7.08359481e-03 6.90846317e-03
  6.75242210e-03 6.61360555e-03 6.49037875e-03 6.38130550e-03
  6.28512075e-03 6.20070745e-03 6.12707703e-03 6.06335283e-03
  6.00875601e-03 5.96259349e-03 5.92424766e-03 5.89316756e-03
  5.86886125e-03 5.85088932e-03 5.83885920e-03 5.83242030e-03
  5.83125984e-03 5.83509913e-03 5.84369055e-03 5.85681472e-03
  5.87427826e-03 5.89591178e-03 5.92156815e-03 5.95112109e-03
  5.98446399e-03 6.02150888e-03 6.06218567e-03 6.10644151e-03
  6.15424036e-03 6.20556265e-03 6.26040515e-03 6.31878095e-03
  6.38071955e-03 6.44626708e-03 6.51548667e-03 6.58845896e-03]]
conditioning:tensor([[0.0000, 0.0000, 0.1960, 0.0000, 0.0995, 0.9755]])
conditioning:('ring_01_freq_reflect_v2_72d9943b-e308-11ef-8c1f-047c16a08772_0-1751_75-78.png',)
