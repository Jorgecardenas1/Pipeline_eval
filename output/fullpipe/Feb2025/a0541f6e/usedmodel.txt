batch:GAN Training
fitness:0.01621817069777092
Predicte:tensor([[-0.0438,  0.0069,  0.0278,  0.0331,  0.0354,  0.0081,  0.0127,  0.0031,
          0.0205,  0.0275,  0.0306,  0.0344,  0.0456,  0.0742,  0.0730,  0.0795,
          0.0619,  0.0505,  0.0070, -0.0143, -0.0256, -0.0059,  0.0307,  0.0764,
          0.1103,  0.1347,  0.1340,  0.1039,  0.0517,  0.0049, -0.0291, -0.0310,
         -0.0282, -0.0146,  0.0082,  0.0267,  0.0189, -0.0263, -0.0601, -0.0635,
         -0.0162,  0.0531,  0.1180,  0.0947,  0.0300,  0.0290,  0.0385,  0.0712,
          0.0552,  0.0202,  0.0435,  0.0527,  0.0341, -0.0220,  0.0126,  0.0614,
          0.1085,  0.1138,  0.0844,  0.0899,  0.0779,  0.0938,  0.0914,  0.0848,
          0.0870,  0.0809,  0.0657,  0.0355, -0.0062, -0.0163, -0.0364, -0.0025,
          0.0583,  0.0821,  0.0722,  0.0942,  0.1023,  0.0867,  0.0827,  0.0868,
          0.0975,  0.1037,  0.1231,  0.1463,  0.1696,  0.1851,  0.1744,  0.1540,
          0.1418,  0.1410,  0.1090,  0.1009,  0.0889,  0.0647,  0.0606,  0.0679,
          0.0574,  0.0493,  0.0452,  0.0237]], device='cuda:0',
       grad_fn=<TanhBackward0>)
latent:[0.668 0.872 0.924 0.862 0.373 0.011 0.446 0.583 0.093 0.406 0.339 0.44
 0.633 0.402 0.611 0.664 0.335 0.789 0.507 0.618 0.584 0.14  0.859 0.504
 0.084 0.427 0.944 0.837 0.277 0.414 0.62  0.516 0.092 0.423 0.458 0.006
 0.527 0.056 0.137 1.    0.199 0.996 0.671 0.531 0.838 0.502 0.547 0.933
 0.308 0.694 0.85  0.471 0.009 0.019 0.767 0.088 0.321 0.005 0.542 0.231
 0.353 0.308 0.415 0.633 0.665 0.958 0.808 0.869 0.928 0.954 0.932 0.022
 0.294 0.444 0.937 0.381 0.901 0.964 0.917 0.863 0.819 0.898 0.738 0.562
 0.784 0.575 0.765 0.627 0.055 0.004 0.405 0.046 0.66  0.77  0.339 0.383
 0.307 0.06  0.385 0.557 0.947 0.852 0.238 0.891 0.816 0.552 0.401 0.093
 0.034 0.66  0.475 0.78  0.684 0.724 0.892 0.309 0.894 0.411 0.317 0.606
 0.12  0.287 0.323 0.537 0.724 0.485 0.067 0.109 0.965 0.169 0.851 0.612
 0.781 0.705 0.143 0.279 0.927 0.454 0.158 0.285 0.426 0.783 0.76  0.311
 0.262 0.641 0.344 0.21  0.996 0.268 0.708 0.437 0.049 0.495 0.766 0.872
 0.383 0.657 0.065 0.716 0.572 0.141 0.275 0.626 0.942 0.999 0.796 0.23
 0.72  0.478 0.309 0.582 0.688 0.324 0.455 0.982 0.712 0.035 0.589 0.852
 0.675 0.7   0.985 0.632 0.645 0.963 0.816 0.742 0.534 0.983 0.749 0.555
 0.954 0.272 0.614 0.262 0.602 0.837 0.376 0.184 0.215 0.219 0.656 0.29
 0.245 0.622 0.247 0.94  0.763 0.102 0.281 0.924 0.132 0.771 0.284 0.211
 0.827 0.593 0.391 0.107 0.538 0.619 0.637 0.139 0.769 0.744 0.637 0.213
 0.534 0.936 0.491 0.431 0.58  0.116 0.432 0.922 0.473 0.348 0.234 0.529
 0.04  0.623 0.06  0.474 0.45  0.603 0.252 0.23  0.6   0.475 0.905 0.203
 0.924 0.7   0.078 0.591 0.656 0.102 0.935 0.766 0.718 0.994 0.565 0.27
 0.285 0.536 0.921 0.621 0.272 0.524 0.655 0.895 0.438 0.389 0.329 0.398
 0.315 0.248 0.365 0.124 0.615 0.016 0.139 0.427 0.408 0.503 0.556 0.112
 0.287 0.096 0.719 0.398 0.316 0.326 0.155 0.334 0.572 0.172 0.635 0.908
 0.654 0.214 0.059 0.906 0.754 0.386 0.94  0.719 0.638 0.715 0.676 0.821
 0.877 0.09  0.9   0.241 0.303 0.553 0.287 0.516 0.927 0.893 0.689 0.676
 0.817 0.916 0.665 0.105 0.157 0.564 0.083 0.941 0.578 0.587 0.226 0.684
 0.713 0.534 0.428 0.576 0.91  0.404 0.704 0.578 0.975 0.57  0.714 0.262
 0.375 0.917 0.572 0.289 0.484 0.477 0.179 0.846 0.58  0.898 0.152 0.833
 0.626 0.209 0.298 0.469 0.672 0.721 0.677 0.063 0.92  0.314 0.558 0.369
 0.733 0.916 0.67  0.8   0.918 0.387 0.104 0.457 0.895 0.597 0.655 0.162
 0.463 0.033 0.275 0.101 0.191 0.643 0.226 0.952 0.422 0.303 0.011 0.633
 0.918 0.401 0.969 0.628]
Truth:[[7.50300000e+01 7.50600000e+01 7.50900000e+01 7.51200000e+01
  7.51500000e+01 7.51800000e+01 7.52100000e+01 7.52400000e+01
  7.52700000e+01 7.53000000e+01 7.53300000e+01 7.53600000e+01
  7.53900000e+01 7.54200000e+01 7.54500000e+01 7.54800000e+01
  7.55100000e+01 7.55400000e+01 7.55700000e+01 7.56000000e+01
  7.56300000e+01 7.56600000e+01 7.56900000e+01 7.57200000e+01
  7.57500000e+01 7.57800000e+01 7.58100000e+01 7.58400000e+01
  7.58700000e+01 7.59000000e+01 7.59300000e+01 7.59600000e+01
  7.59900000e+01 7.60200000e+01 7.60500000e+01 7.60800000e+01
  7.61100000e+01 7.61400000e+01 7.61700000e+01 7.62000000e+01
  7.62300000e+01 7.62600000e+01 7.62900000e+01 7.63200000e+01
  7.63500000e+01 7.63800000e+01 7.64100000e+01 7.64400000e+01
  7.64700000e+01 7.65000000e+01 7.65300000e+01 7.65600000e+01
  7.65900000e+01 7.66200000e+01 7.66500000e+01 7.66800000e+01
  7.67100000e+01 7.67400000e+01 7.67700000e+01 7.68000000e+01
  7.68300000e+01 7.68600000e+01 7.68900000e+01 7.69200000e+01
  7.69500000e+01 7.69800000e+01 7.70100000e+01 7.70400000e+01
  7.70700000e+01 7.71000000e+01 7.71300000e+01 7.71600000e+01
  7.71900000e+01 7.72200000e+01 7.72500000e+01 7.72800000e+01
  7.73100000e+01 7.73400000e+01 7.73700000e+01 7.74000000e+01
  7.74300000e+01 7.74600000e+01 7.74900000e+01 7.75200000e+01
  7.75500000e+01 7.75800000e+01 7.76100000e+01 7.76400000e+01
  7.76700000e+01 7.77000000e+01 7.77300000e+01 7.77600000e+01
  7.77900000e+01 7.78200000e+01 7.78500000e+01 7.78800000e+01
  7.79100000e+01 7.79400000e+01 7.79700000e+01 7.80000000e+01]
 [3.13248256e-03 3.17500589e-03 3.21733219e-03 3.25988867e-03
  3.30307148e-03 3.34724937e-03 3.39276738e-03 3.43995054e-03
  3.48910763e-03 3.54053507e-03 3.59452089e-03 3.65134881e-03
  3.71130255e-03 3.77467031e-03 3.84174957e-03 3.91285220e-03
  3.98830997e-03 4.06848059e-03 4.15375436e-03 4.24456154e-03
  4.34138065e-03 4.44474790e-03 4.55526788e-03 4.67362605e-03
  4.80060311e-03 4.93709189e-03 5.08411740e-03 5.24286052e-03
  5.41468652e-03 5.60117946e-03 5.80418399e-03 6.02585653e-03
  6.26872847e-03 6.53578457e-03 6.83056130e-03 7.15727078e-03
  7.52095877e-03 7.92770739e-03 8.38489808e-03 8.90155600e-03
  9.48880596e-03 1.01604833e-02 1.09339624e-02 1.18312968e-02
  1.28808099e-02 1.41193539e-02 1.55955730e-02 1.73747138e-02
  1.95458747e-02 2.22332002e-02 2.56136498e-02 2.99460820e-02
  3.56205328e-02 4.32450227e-02 5.38052638e-02 6.89728422e-02
  9.17301150e-02 1.27692816e-01 1.87925728e-01 2.94003202e-01
  4.76841349e-01 6.99580357e-01 7.07432966e-01 4.85657810e-01
  2.96796791e-01 1.87220341e-01 1.25540456e-01 8.90777373e-02
  6.62216141e-02 5.11215533e-02 4.06944379e-02 3.32246827e-02
  2.77072759e-02 2.35259909e-02 2.02876818e-02 1.77327337e-02
  1.56844926e-02 1.40195611e-02 1.26497290e-02 1.15106357e-02
  1.05544553e-02 9.74505986e-03 9.05474843e-03 8.46199061e-03
  7.94984136e-03 7.50480868e-03 7.11603254e-03 6.77468126e-03
  6.47350196e-03 6.20648194e-03 5.96859070e-03 5.75558151e-03
  5.56383730e-03 5.39024991e-03 5.23212474e-03 5.08710484e-03
  4.95311012e-03 4.82828820e-03 4.71097458e-03 4.59966008e-03]]
conditioning:tensor([[0.1984, 0.0000, 0.0000, 0.0000, 0.1008, 0.9749]])
conditioning:('circ_01_freq_reflect_v2_6108e629-c8ff-11ef-898c-047c16a08772_0-579_75-78.png',)
