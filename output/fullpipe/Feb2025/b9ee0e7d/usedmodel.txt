batch:GAN Training
fitness:0.04324142025073563
Predicte:tensor([[-5.3563e-02, -2.0813e-02, -4.8917e-03,  2.3060e-06,  2.9182e-03,
         -4.1549e-03, -8.7535e-03, -1.9588e-02, -2.9727e-03, -7.1858e-05,
          2.5416e-02,  6.1166e-02,  1.0725e-01,  1.4830e-01,  1.6474e-01,
          1.4863e-01,  1.4182e-01,  9.3758e-02,  8.7217e-02,  8.6592e-02,
          9.4445e-02,  1.0572e-01,  1.0021e-01,  9.5351e-02,  9.1848e-02,
          1.1648e-01,  1.1492e-01,  9.7548e-02,  5.8468e-02,  2.7900e-02,
          2.7948e-02,  4.5507e-02,  5.7232e-02,  6.2894e-02,  3.9094e-02,
          1.4694e-02, -2.4758e-03,  1.9819e-02,  2.6317e-02,  2.7332e-02,
          4.8954e-02,  8.6551e-02,  1.5455e-01,  1.3716e-01,  6.0987e-02,
          4.5656e-02,  5.4348e-02,  1.0536e-01,  1.8535e-01,  1.2725e-01,
          1.0341e-01,  1.0218e-01,  1.3684e-01,  1.7774e-01,  2.1016e-01,
          2.5889e-01,  2.4385e-01,  2.0820e-01,  1.7896e-01,  1.8175e-01,
          1.8521e-01,  2.2512e-01,  2.1350e-01,  1.9546e-01,  1.7047e-01,
          1.3827e-01,  1.1271e-01,  1.0148e-01,  8.9914e-02,  7.7292e-02,
          8.9662e-02,  1.1462e-01,  1.5785e-01,  1.7421e-01,  1.9368e-01,
          2.0716e-01,  2.3335e-01,  2.4547e-01,  2.4836e-01,  2.6205e-01,
          2.7068e-01,  2.5317e-01,  2.4683e-01,  2.5541e-01,  2.7692e-01,
          2.9212e-01,  2.7350e-01,  2.5254e-01,  2.1327e-01,  1.7709e-01,
          1.4284e-01,  1.3358e-01,  1.0613e-01,  8.8918e-02,  8.0664e-02,
          7.2672e-02,  7.1977e-02,  4.8278e-02,  4.3331e-02,  2.9455e-02]],
       device='cuda:0', grad_fn=<TanhBackward0>)
latent:[-0.     0.885  0.04   0.988  0.004  0.005 -0.     0.986  0.022  0.116
  0.149  0.936  0.67   0.964  0.117  0.049  0.977  0.175  0.011  0.079
  0.023  0.88   0.945  0.033  0.887  0.945  0.958  0.273  0.956  0.158
  0.999  0.009  0.007  0.071  0.95   0.012  0.99   0.651  0.988  0.128
  0.13   0.984  0.004  0.988  0.797  0.977  0.061  0.997  0.971  0.071
  0.383  0.1    0.646  0.212  0.564  0.985  0.903  0.412  0.3    0.16
  0.813  0.     0.256  0.9    0.069  0.005  0.213  1.     0.988  0.993
  0.759  0.046  0.004  1.     0.97   0.967  0.026  0.035  0.109  0.957
  0.979  0.955  0.539  0.039  0.894  0.563  0.063  0.476  0.993  0.988
  0.933  0.212  0.102  0.839  0.014  0.054  0.618  0.075  0.014  0.005
  0.983  0.806  0.946  0.877  0.948  0.044  0.983  0.582  0.002  0.03
  0.584  0.006  0.926  0.776  0.913  0.025  0.987  0.395  0.87   0.414
  0.977  0.456  0.085  0.062  0.018  0.917  0.251  0.002  0.046  0.022
  0.991  0.043  0.055  0.003  0.969  0.047  0.02   0.966  0.985  0.944
  0.991  0.255  0.997  0.005  0.131  0.904  0.983  0.988  0.914  0.143
  0.477  0.029  0.385  0.164  0.998  0.979  0.913  0.857  0.912  0.686
  0.108  0.308  0.931  0.342  0.169  0.603  0.991  0.336  0.97   0.978
  0.082  0.04   0.008  1.     0.903  0.904  0.075  0.99   0.431  0.037
  0.153  0.983  0.938  0.002  0.729  0.954  0.867  0.002  0.959  0.008
  0.007  0.729  0.998  0.083  0.002  0.944  0.995  0.001  0.656  0.92
  0.348  0.218  0.98   0.408  0.558  0.004  0.008  0.904  0.259  0.851
  0.156  0.525  0.987  0.427  0.53   0.042  0.987  0.027  0.122  0.963
  0.996  0.034  0.934  0.065  0.268  0.153 -0.     0.869  0.987  0.948
  0.923 -0.     0.993  0.022  0.946  0.042  0.986  0.103  0.054  0.665
  0.121  0.045  0.968  0.019  1.     0.908  0.009  0.998  0.006  0.977
  0.899  0.466  0.826  0.015  0.967  0.209  0.973  0.054  0.847  0.702
  0.81   0.991  0.296  0.329  0.942  0.015  0.022  0.981  0.976  0.05
  0.455  0.004  0.002  0.589  0.473  0.029  0.645  0.585  0.493  0.549
  0.38   0.007  0.118  0.175  0.981  0.004  0.01  -0.     0.286  0.011
  0.09   0.968  0.921  1.     0.984  0.948  0.269  0.837  0.023  0.008
  0.941  0.481  0.022  0.027  0.029  0.99   0.985  0.041  0.001  0.012
  0.154  0.989  0.01   0.32   0.019  0.057  1.     0.045  0.993  0.191
  0.022  0.891  0.003  0.008  0.989  0.919  0.097  0.894  0.992  0.024
  0.017  0.988  0.015  0.043  0.002  0.368  0.487  0.963  0.027  0.994
  0.002  0.023  0.792  0.927  0.369  0.293  0.468  0.066  0.992  0.017
  0.975  0.007  0.026  0.79   0.371  0.791  0.999  0.029  0.01   0.967
  0.023  0.046  0.912  0.91   1.     0.968  0.235  0.597  0.534  0.081
  0.966  0.006  0.441  0.962  0.585  0.256  0.831  0.847  0.889  0.068
  0.861  0.823  0.476  0.991  0.96   0.056  0.927  0.575  0.097  0.001
  0.01   0.091  0.029  0.011  0.703  0.025  0.059  0.229  0.922  0.083]
Truth:[[7.50300000e+01 7.50600000e+01 7.50900000e+01 7.51200000e+01
  7.51500000e+01 7.51800000e+01 7.52100000e+01 7.52400000e+01
  7.52700000e+01 7.53000000e+01 7.53300000e+01 7.53600000e+01
  7.53900000e+01 7.54200000e+01 7.54500000e+01 7.54800000e+01
  7.55100000e+01 7.55400000e+01 7.55700000e+01 7.56000000e+01
  7.56300000e+01 7.56600000e+01 7.56900000e+01 7.57200000e+01
  7.57500000e+01 7.57800000e+01 7.58100000e+01 7.58400000e+01
  7.58700000e+01 7.59000000e+01 7.59300000e+01 7.59600000e+01
  7.59900000e+01 7.60200000e+01 7.60500000e+01 7.60800000e+01
  7.61100000e+01 7.61400000e+01 7.61700000e+01 7.62000000e+01
  7.62300000e+01 7.62600000e+01 7.62900000e+01 7.63200000e+01
  7.63500000e+01 7.63800000e+01 7.64100000e+01 7.64400000e+01
  7.64700000e+01 7.65000000e+01 7.65300000e+01 7.65600000e+01
  7.65900000e+01 7.66200000e+01 7.66500000e+01 7.66800000e+01
  7.67100000e+01 7.67400000e+01 7.67700000e+01 7.68000000e+01
  7.68300000e+01 7.68600000e+01 7.68900000e+01 7.69200000e+01
  7.69500000e+01 7.69800000e+01 7.70100000e+01 7.70400000e+01
  7.70700000e+01 7.71000000e+01 7.71300000e+01 7.71600000e+01
  7.71900000e+01 7.72200000e+01 7.72500000e+01 7.72800000e+01
  7.73100000e+01 7.73400000e+01 7.73700000e+01 7.74000000e+01
  7.74300000e+01 7.74600000e+01 7.74900000e+01 7.75200000e+01
  7.75500000e+01 7.75800000e+01 7.76100000e+01 7.76400000e+01
  7.76700000e+01 7.77000000e+01 7.77300000e+01 7.77600000e+01
  7.77900000e+01 7.78200000e+01 7.78500000e+01 7.78800000e+01
  7.79100000e+01 7.79400000e+01 7.79700000e+01 7.80000000e+01]
 [6.42644128e-03 6.61370007e-03 6.82233735e-03 7.05286286e-03
  7.30590484e-03 7.58222004e-03 7.88270540e-03 8.20841126e-03
  8.56055668e-03 8.94054701e-03 9.34999425e-03 9.79074051e-03
  1.02648853e-02 1.07748171e-02 1.13232506e-02 1.19132693e-02
  1.25483766e-02 1.32325548e-02 1.39703355e-02 1.47668824e-02
  1.56280898e-02 1.65607005e-02 1.75724459e-02 1.86722157e-02
  1.98702619e-02 2.11784470e-02 2.26105461e-02 2.41826175e-02
  2.59134596e-02 2.78251767e-02 2.99438847e-02 3.23005966e-02
  3.49323407e-02 3.78835822e-02 4.12080446e-02 4.49710586e-02
  4.92526175e-02 5.41513812e-02 5.97899672e-02 6.63219984e-02
  7.39415687e-02 8.28960512e-02 9.35035466e-02 1.06176773e-01
  1.21455843e-01 1.40053092e-01 1.62913617e-01 1.91294554e-01
  2.26861819e-01 2.71788854e-01 3.28802870e-01 4.01029596e-01
  4.91290315e-01 6.00201268e-01 7.22344361e-01 8.41209914e-01
  9.28221180e-01 9.54483587e-01 9.11629788e-01 8.18575913e-01
  7.05334433e-01 5.94972561e-01 4.98646372e-01 4.19091027e-01
  3.55033538e-01 3.03915153e-01 2.63125743e-01 2.30430312e-01
  2.04045409e-01 1.82590816e-01 1.65010951e-01 1.50500208e-01
  1.38441813e-01 1.28360692e-01 1.19888121e-01 1.12735513e-01
  1.06675015e-01 1.01525141e-01 9.71400627e-02 9.34015899e-02
  9.02131139e-02 8.74950066e-02 8.51810931e-02 8.32159305e-02
  8.15526934e-02 8.01515189e-02 7.89782043e-02 7.80031772e-02
  7.72006757e-02 7.65480961e-02 7.60254699e-02 7.56150461e-02
  7.53009569e-02 7.50689506e-02 7.49061788e-02 7.48010286e-02
  7.47429898e-02 7.47225522e-02 7.47311250e-02 7.47609758e-02]]
conditioning:tensor([[0.0000, 0.0000, 0.0000, 0.1958, 0.0995, 0.9756]])
conditioning:('splitcross_01_freq_reflect_v2_f3a9a3ac-e28a-11ef-9153-047c16a08772_0-1918_75-78.png',)
