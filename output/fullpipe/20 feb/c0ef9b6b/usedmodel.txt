batch:GAN Training
fitness:0.02828446192095505
Predicted:tensor([[ 0.0719,  0.0429,  0.0232,  0.0192,  0.0415,  0.0511,  0.0535,  0.0467,
          0.0414,  0.0226,  0.0197,  0.0283,  0.0280, -0.0006,  0.0096, -0.0041,
         -0.0082,  0.0053,  0.0425,  0.0586,  0.0451,  0.0182,  0.0471,  0.1229,
          0.1092,  0.0721,  0.0488,  0.0389,  0.0338,  0.0254,  0.0097,  0.0345,
          0.0544,  0.0212, -0.0139,  0.0092,  0.0220,  0.0143,  0.0068,  0.0105,
          0.0158,  0.0204,  0.0281,  0.0020, -0.0042,  0.0210,  0.0438,  0.0135,
         -0.0433,  0.0202,  0.0473,  0.0555,  0.0468,  0.0328,  0.0450,  0.0440,
          0.0244,  0.0529,  0.0554,  0.0112,  0.0019,  0.0282,  0.0111, -0.0013,
         -0.0053,  0.0116,  0.0376,  0.0531,  0.0677,  0.0856,  0.0549,  0.0614,
          0.0984,  0.0879,  0.0502,  0.0456,  0.0512,  0.0524,  0.0548,  0.0822,
          0.1096,  0.1089,  0.1033,  0.0924,  0.0822,  0.0960,  0.1099,  0.0853,
          0.0518,  0.0429,  0.0426,  0.0353,  0.0363,  0.0570,  0.0654,  0.0609,
          0.0634,  0.0367,  0.0180,  0.0073]], device='cuda:0',
       grad_fn=<TanhBackward0>)
latent:[-1.32941096 -1.19526738  0.23154265  0.75971665 -1.52322768  0.75986827
 -0.97579426 -0.60816876 -0.85899367 -0.22957625  0.25057279  0.98865383
 -0.66598227 -2.96848436 -0.55638971  0.99036221 -3.53885014 -0.11036229
 -4.5023909   0.74976133  1.32059276 -3.78716637 -0.08790593 -1.67044231
 -2.45883321 -0.50333237  1.88305484  0.35529329 -3.25879204  1.0136789
 -1.18917285  6.06345365 -0.75902706  0.52761878 -1.37457948  2.85874335
 -3.25367807 -0.55709265 -2.69385288  2.62461857 -3.00093255 -1.11638627
 -3.36850575 -2.24934917  0.94569067  2.36392299 -1.54003219  1.43642389
 -0.44968932 -0.48833384 -1.26812601 -1.06304552  2.42500816  0.23812984
 -1.37316411 -0.84748409 -0.90037261 -3.07877553  0.51783888 -2.44108688
 -0.9935189  -2.27868494 -1.03304322 -1.34122099 -0.73180834  0.19831099
 -0.64192929  0.45418672 -1.95574955 -4.62481864 -1.399534    0.49891118
 -2.06328245 -0.68292147  4.09282117 -0.67892325 -3.06394132 -2.41391363
  1.87215609 -2.60892979  1.49500341 -0.4083737  -2.51834244 -5.14812552
  0.25653557 -0.98610206 -1.46433496 -0.18231537  1.74743689 -2.14346264
 -3.68913963 -5.83294991  0.60593054 -0.37556201 -2.4677945  -2.36404759
 -0.63984279 -2.28801184 -0.23608751 -1.26868528 -0.64585887 -2.09648232
 -0.39089378 -3.66349137 -2.18774051 -2.62123536  1.17582025 -1.80380922
 -1.37779894 -2.41877576 -2.09438275 -1.86230592 -0.12844075 -1.59292888
 -0.22226209 -1.00057446  0.61320748 -4.52854403 -2.40272661 -3.13860758
  0.94096516  0.07297785 -0.53032921 -3.86092759 -0.39786895 -2.13284533
 -0.33369379 -1.01353057 -0.72937918 -1.9405415  -0.42520353 -2.41444689
  0.32587708 -4.04050042 -1.23802703  0.93634191  0.36704795  0.05322335
 -1.38842988 -1.21424997  0.42813099 -2.56230881 -1.80679054 -1.92719778
 -2.23325474 -0.25746983 -1.26511951  0.72946356 -3.96384203  1.60958244
  1.89931103 -3.45567457 -0.14637995 -0.47613687 -4.55734266 -2.8003249
 -2.28683482 -5.09037457  0.77280708  3.16114142 -1.3007675  -5.71994655
 -1.84574983 -2.43281285 -2.43158501  1.46557427  0.13833667 -0.83782117
  3.66272252 -2.53174982  0.20769786 -1.37629562 -5.05462354  0.26641502
 -1.58026302  0.83251627 -2.4364503  -2.78234166  2.78819426 -2.70368344
  0.09628806  0.31072658 -0.54100905 -1.24736247 -0.30259965 -1.8252821
 -2.59582621 -0.53824534 -2.6357404  -2.37074336  0.72021892 -1.80206174
 -0.37300267 -2.15215271 -2.22373377  0.47008469 -0.67029205 -3.43875073
 -1.37515387 -1.72423813 -1.10427928 -2.49149877  0.38869167 -3.52908452
 -4.62235412 -0.45000578 -2.82752608  1.00022721 -2.64478348  1.21480826
 -0.52488311 -1.40578929 -1.50188903 -0.01837777  1.57453525 -0.32712843
  2.37293352 -2.29511606 -0.10578184 -1.33614234 -2.12977165  0.55073145
  2.32675029 -2.74891671 -1.29054102  1.60703135 -1.98034665  2.11032343
 -0.30062163  0.46021638  1.79060029 -3.43373092 -0.37022546 -2.0759775
 -2.93076519 -0.71937945 -3.21624414 -1.22968709  0.23787104 -2.24831016
 -0.82704474 -3.37189726  0.94579219 -2.83559592 -0.38201863 -2.49482121
  2.54742646  1.64154197 -0.24991808  0.14848914 -1.86437268  0.42267522
  2.60639957  0.88664228 -2.99320608 -2.11316679  1.2790294  -0.58369563
 -2.79177491  1.61082734 -1.72335219  0.6642903  -1.73060559 -2.49749424
 -0.84866549  0.84458911 -3.10662586 -1.75090197 -1.95277216 -0.95521802
  0.68942939 -2.13828168 -1.36298372  2.30332575 -1.69678032  0.94881641
 -2.31656692 -0.84992681  2.9786191  -2.23567244 -3.49445833 -1.58571846
  0.89842292  0.61823396 -0.27775268 -3.26291626 -3.14731658 -0.59908325
 -3.14964949 -3.51425883 -3.14366249  2.37115264 -3.04696803  2.91266319
  0.53238821 -1.32833603  1.46355198 -0.67644389 -0.7400925   2.30217477
 -3.20465961 -1.84617601 -0.47706368 -3.02565916 -1.36875148 -2.18566817
  0.99608553  2.08958694 -2.73939033  0.69954433 -0.6607316  -0.91016042
  0.25531899 -3.96868943 -0.92343788 -4.1862182  -1.73061256  2.28818896
  1.06264709 -4.6909695  -0.24592847  0.23393887  0.3471409   3.3221304
 -3.39845504  0.0330323   0.21252244 -1.70589654 -4.01836342 -2.65965039
 -3.10911817 -2.19102865 -1.85834546 -1.81134175 -1.16715776 -2.97765039
  0.23448867 -1.30876612 -0.34873536  1.06754384 -1.62734677 -2.88792371
  0.95039993 -3.2781889  -0.37808089 -3.56309277 -3.4685105  -2.92121913
 -0.88558697 -1.87170767 -1.29768014 -1.10877689 -2.35005066  2.66315401
 -3.51489662  2.55112208 -1.61212852  0.03443133 -0.96054343  0.06919223
 -1.12682712 -3.33412124 -0.8944516   1.17738131  0.5472403  -3.04446184
 -1.88247964  1.23335786 -0.25033699  0.88322883 -2.01610556 -0.04591511
 -2.49194772  0.54348143 -0.47565181 -0.73708205 -0.68302209 -0.91057368
  0.77043207 -0.92656137 -3.79699958 -1.20923655  0.48432743 -0.01268477
  0.35053506 -2.26078888  1.05547945  0.2092813   0.56334365 -2.09081906
  0.82703237 -3.83211926 -2.63599564 -4.57631202  2.0695967  -1.30139121
  0.69060359 -1.20739908  1.16838209 -3.55778242]
Truth:[[7.50300000e+01 7.50600000e+01 7.50900000e+01 7.51200000e+01
  7.51500000e+01 7.51800000e+01 7.52100000e+01 7.52400000e+01
  7.52700000e+01 7.53000000e+01 7.53300000e+01 7.53600000e+01
  7.53900000e+01 7.54200000e+01 7.54500000e+01 7.54800000e+01
  7.55100000e+01 7.55400000e+01 7.55700000e+01 7.56000000e+01
  7.56300000e+01 7.56600000e+01 7.56900000e+01 7.57200000e+01
  7.57500000e+01 7.57800000e+01 7.58100000e+01 7.58400000e+01
  7.58700000e+01 7.59000000e+01 7.59300000e+01 7.59600000e+01
  7.59900000e+01 7.60200000e+01 7.60500000e+01 7.60800000e+01
  7.61100000e+01 7.61400000e+01 7.61700000e+01 7.62000000e+01
  7.62300000e+01 7.62600000e+01 7.62900000e+01 7.63200000e+01
  7.63500000e+01 7.63800000e+01 7.64100000e+01 7.64400000e+01
  7.64700000e+01 7.65000000e+01 7.65300000e+01 7.65600000e+01
  7.65900000e+01 7.66200000e+01 7.66500000e+01 7.66800000e+01
  7.67100000e+01 7.67400000e+01 7.67700000e+01 7.68000000e+01
  7.68300000e+01 7.68600000e+01 7.68900000e+01 7.69200000e+01
  7.69500000e+01 7.69800000e+01 7.70100000e+01 7.70400000e+01
  7.70700000e+01 7.71000000e+01 7.71300000e+01 7.71600000e+01
  7.71900000e+01 7.72200000e+01 7.72500000e+01 7.72800000e+01
  7.73100000e+01 7.73400000e+01 7.73700000e+01 7.74000000e+01
  7.74300000e+01 7.74600000e+01 7.74900000e+01 7.75200000e+01
  7.75500000e+01 7.75800000e+01 7.76100000e+01 7.76400000e+01
  7.76700000e+01 7.77000000e+01 7.77300000e+01 7.77600000e+01
  7.77900000e+01 7.78200000e+01 7.78500000e+01 7.78800000e+01
  7.79100000e+01 7.79400000e+01 7.79700000e+01 7.80000000e+01]
 [1.61894083e-02 1.64465386e-02 1.67565161e-02 1.71333437e-02
  1.75956445e-02 1.81687284e-02 1.88878432e-02 1.98034771e-02
  2.09903695e-02 2.25635989e-02 2.47090770e-02 2.77457815e-02
  3.22651545e-02 3.94832471e-02 5.22837148e-02 7.90460946e-02
  1.52229823e-01 4.33795749e-01 9.58761796e-01 9.81461571e-01
  8.32660569e-01 3.39630126e-01 1.43153223e-01 7.65940909e-02
  4.92451784e-02 3.63061176e-02 3.01469364e-02 2.88406628e-02
  3.57677002e-02 7.43052805e-02 6.03834651e-02 2.40185283e-02
  1.58320755e-02 1.29149650e-02 1.14559821e-02 1.05631163e-02
  9.94463621e-03 9.48066795e-03 9.11328707e-03 8.81095962e-03
  8.55491015e-03 8.33316994e-03 8.13769651e-03 7.96285793e-03
  7.80457887e-03 7.65983118e-03 7.52631531e-03 7.40225299e-03
  7.28624770e-03 7.17718805e-03 7.07417925e-03 6.97649346e-03
  6.88353314e-03 6.79480365e-03 6.70989230e-03 6.62845240e-03
  6.55019073e-03 6.47485770e-03 6.40223965e-03 6.33215260e-03
  6.26443726e-03 6.19895497e-03 6.13558442e-03 6.07421894e-03
  6.01476424e-03 5.95713661e-03 5.90126135e-03 5.84707146e-03
  5.79450664e-03 5.74351229e-03 5.69403882e-03 5.64604094e-03
  5.59947714e-03 5.55430921e-03 5.51050183e-03 5.46802225e-03
  5.42683996e-03 5.38692646e-03 5.34825501e-03 5.31080049e-03
  5.27453921e-03 5.23944876e-03 5.20550791e-03 5.17269650e-03
  5.14099535e-03 5.11038621e-03 5.08085166e-03 5.05237507e-03
  5.02494057e-03 4.99853302e-03 4.97313796e-03 4.94874160e-03
  4.92533081e-03 4.90289311e-03 4.88141667e-03 4.86089031e-03
  4.84130350e-03 4.82264639e-03 4.80490978e-03 4.78808522e-03]]
initial conditioning:tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.5080, 5.1245]])
final conditioning:tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.5080, 5.1087]])
initial conditioning:5.026
final conditioning:tensor(5.1087)
